{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepfake Detection: Proof of Concept with Feature Extraction and Modeling\n",
    "## Team Quarks (Ali & Belal)\n",
    "## Objective\n",
    "The objective of this notebook is to test a proof of concept for deepfake detection. We will employ basic machine learning models to assess the predictive power of the facial landmark variance feature, which was identified as a potential indicator during our EDA.\n",
    "## Data Description\n",
    "The dataset consists of facial landmark data extracted from a series of videos. Each entry in the dataset represents a video and includes the variance of facial landmark velocities in the X and Y axes, as well as the percentage of frames in which a face was successfully detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     video_name  Chin X-Axis Velocity Variance  Chin Y-Axis Velocity Variance  \\\n",
      "0    wvrzowftpz                       0.096015                       0.328666   \n",
      "1    spoezekgpo                       1.402898                      14.888691   \n",
      "2    zocvwatcsf                       0.237263                       0.784404   \n",
      "3    ksdohprrko                     244.722785                     177.297338   \n",
      "4    vzwjztahsh                       0.476414                       2.015065   \n",
      "..          ...                            ...                            ...   \n",
      "250  wzgbtkbgkg                       2.250000                       0.778547   \n",
      "251  fgmqrobblg                       3.213788                      10.255761   \n",
      "252  odvqbtoczb                       0.435622                       8.914122   \n",
      "253  bxriwqpced                       0.429208                       0.912364   \n",
      "254  hyqszrnkhz                       0.540259                       1.310818   \n",
      "\n",
      "     Left Eyebrow X-Axis Velocity Variance  \\\n",
      "0                                 0.223316   \n",
      "1                                34.941649   \n",
      "2                                 0.431597   \n",
      "3                                77.458594   \n",
      "4                                 1.112708   \n",
      "..                                     ...   \n",
      "250                               0.810000   \n",
      "251                               9.846667   \n",
      "252                               0.533587   \n",
      "253                               0.506597   \n",
      "254                               0.841649   \n",
      "\n",
      "     Left Eyebrow Y-Axis Velocity Variance  \\\n",
      "0                                 0.130000   \n",
      "1                               167.936927   \n",
      "2                                 0.512483   \n",
      "3                                60.579983   \n",
      "4                                 0.764983   \n",
      "..                                     ...   \n",
      "250                               3.610000   \n",
      "251                               2.916042   \n",
      "252                               2.372885   \n",
      "253                               0.145000   \n",
      "254                               0.752760   \n",
      "\n",
      "     Right Eyebrow X-Axis Velocity Variance  \\\n",
      "0                                  0.240816   \n",
      "1                                 17.991927   \n",
      "2                                  0.351597   \n",
      "3                                 31.288056   \n",
      "4                                  1.184983   \n",
      "..                                      ...   \n",
      "250                                0.160000   \n",
      "251                                6.535000   \n",
      "252                                0.452944   \n",
      "253                                0.244427   \n",
      "254                                1.067708   \n",
      "\n",
      "     Right Eyebrow Y-Axis Velocity Variance  \\\n",
      "0                                  0.214931   \n",
      "1                                 47.189722   \n",
      "2                                  0.524149   \n",
      "3                                 72.635816   \n",
      "4                                  0.696597   \n",
      "..                                      ...   \n",
      "250                                0.010000   \n",
      "251                                1.903316   \n",
      "252                                2.901738   \n",
      "253                                0.164931   \n",
      "254                                0.744167   \n",
      "\n",
      "     Nose Bridge X-Axis Velocity Variance  \\\n",
      "0                                0.240858   \n",
      "1                                2.502170   \n",
      "2                                0.179688   \n",
      "3                                5.747287   \n",
      "4                                0.583225   \n",
      "..                                    ...   \n",
      "250                              0.015625   \n",
      "251                              1.441379   \n",
      "252                              1.842860   \n",
      "253                              0.424371   \n",
      "254                              0.547499   \n",
      "\n",
      "     Nose Bridge Y-Axis Velocity Variance  Nose Tip X-Axis Velocity Variance  \\\n",
      "0                                0.416667                           0.254149   \n",
      "1                                9.921875                           1.373264   \n",
      "2                                0.861979                           0.244149   \n",
      "3                               29.426649                          16.294931   \n",
      "4                                0.829834                           0.521597   \n",
      "..                                    ...                                ...   \n",
      "250                              0.390625                           0.360000   \n",
      "251                              1.700087                           1.003333   \n",
      "252                              1.274379                           1.858115   \n",
      "253                              0.382378                           0.172899   \n",
      "254                              0.886041                           0.434427   \n",
      "\n",
      "     ...  Left Eye X-Axis Velocity Variance  \\\n",
      "0    ...                           0.120841   \n",
      "1    ...                          32.108025   \n",
      "2    ...                           0.216435   \n",
      "3    ...                         114.459672   \n",
      "4    ...                           0.910831   \n",
      "..   ...                                ...   \n",
      "250  ...                           0.444444   \n",
      "251  ...                           5.429097   \n",
      "252  ...                           0.434137   \n",
      "253  ...                           0.427035   \n",
      "254  ...                           0.624988   \n",
      "\n",
      "     Left Eye Y-Axis Velocity Variance  Right Eye X-Axis Velocity Variance  \\\n",
      "0                             0.161844                            0.224103   \n",
      "1                            57.855276                            8.215230   \n",
      "2                             0.655044                            0.200231   \n",
      "3                            33.468316                           18.322037   \n",
      "4                             0.556665                            0.716616   \n",
      "..                                 ...                                 ...   \n",
      "250                           3.062500                            0.062500   \n",
      "251                          10.496335                            6.082128   \n",
      "252                           3.014447                            0.559289   \n",
      "253                           0.239535                            0.243634   \n",
      "254                           0.544837                            0.554000   \n",
      "\n",
      "     Right Eye Y-Axis Velocity Variance  Top Lip X-Axis Velocity Variance  \\\n",
      "0                              0.145833                          0.089238   \n",
      "1                             13.819143                          1.522470   \n",
      "2                              0.560571                          0.213659   \n",
      "3                             55.828511                         44.196105   \n",
      "4                              0.467870                          0.918065   \n",
      "..                                  ...                               ...   \n",
      "250                            0.111111                          0.444444   \n",
      "251                           10.722029                          1.094317   \n",
      "252                            3.258948                          1.597831   \n",
      "253                            0.231433                          0.189498   \n",
      "254                            0.776801                          0.745416   \n",
      "\n",
      "     Top Lip Y-Axis Velocity Variance  Bottom Lip X-Axis Velocity Variance  \\\n",
      "0                            0.179784                             0.197290   \n",
      "1                            1.187690                             1.857274   \n",
      "2                            0.700952                             0.253542   \n",
      "3                          178.937979                            59.605216   \n",
      "4                            0.334174                             0.897060   \n",
      "..                                ...                                  ...   \n",
      "250                          1.460069                             1.265625   \n",
      "251                          1.002673                             1.390866   \n",
      "252                          3.270402                             1.636434   \n",
      "253                          0.178238                             0.323203   \n",
      "254                          0.341134                             0.916278   \n",
      "\n",
      "     Bottom Lip Y-Axis Velocity Variance  Face Detection Percentage  \\\n",
      "0                               0.126917                      100.0   \n",
      "1                               3.523410                      100.0   \n",
      "2                               0.827209                      100.0   \n",
      "3                             253.550634                      100.0   \n",
      "4                               0.612654                      100.0   \n",
      "..                                   ...                        ...   \n",
      "250                             2.376736                       12.0   \n",
      "251                             2.290787                      100.0   \n",
      "252                             4.416312                       86.0   \n",
      "253                             0.243043                      100.0   \n",
      "254                             0.731192                      100.0   \n",
      "\n",
      "     Video Authenticity Label  \n",
      "0                        FAKE  \n",
      "1                        REAL  \n",
      "2                        REAL  \n",
      "3                        REAL  \n",
      "4                        REAL  \n",
      "..                        ...  \n",
      "250                      FAKE  \n",
      "251                      REAL  \n",
      "252                      FAKE  \n",
      "253                      FAKE  \n",
      "254                      REAL  \n",
      "\n",
      "[255 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def create_dataframe_from_json(directory):\n",
    "    data = []\n",
    "    errors = []\n",
    "\n",
    "    # List all files in the given directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "\n",
    "            try:\n",
    "                # Read the JSON file\n",
    "                with open(file_path, 'r') as file:\n",
    "                    json_data = json.load(file)\n",
    "                    \n",
    "                # Start the dictionary with the video name\n",
    "                video_data = {'video_name': filename.replace('.json', '')}\n",
    "                # Update this dictionary with the overall_features\n",
    "                video_data.update(json_data.get(\"overall_features\", {}))\n",
    "\n",
    "                data.append(video_data)\n",
    "\n",
    "            except Exception as e:\n",
    "                errors.append((filename, str(e)))\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Rename columns to be more descriptive\n",
    "    column_renaming = {\n",
    "        'chin_xvel_var': 'Chin X-Axis Velocity Variance',\n",
    "        'chin_yvel_var': 'Chin Y-Axis Velocity Variance',\n",
    "        'left_eyebrow_xvel_var': 'Left Eyebrow X-Axis Velocity Variance',\n",
    "        'left_eyebrow_yvel_var': 'Left Eyebrow Y-Axis Velocity Variance',\n",
    "        'right_eyebrow_xvel_var': 'Right Eyebrow X-Axis Velocity Variance',\n",
    "        'right_eyebrow_yvel_var': 'Right Eyebrow Y-Axis Velocity Variance',\n",
    "        'nose_bridge_xvel_var': 'Nose Bridge X-Axis Velocity Variance',\n",
    "        'nose_bridge_yvel_var': 'Nose Bridge Y-Axis Velocity Variance',\n",
    "        'nose_tip_xvel_var': 'Nose Tip X-Axis Velocity Variance',\n",
    "        'nose_tip_yvel_var': 'Nose Tip Y-Axis Velocity Variance',\n",
    "        'left_eye_xvel_var': 'Left Eye X-Axis Velocity Variance',\n",
    "        'left_eye_yvel_var': 'Left Eye Y-Axis Velocity Variance',\n",
    "        'right_eye_xvel_var': 'Right Eye X-Axis Velocity Variance',\n",
    "        'right_eye_yvel_var': 'Right Eye Y-Axis Velocity Variance',\n",
    "        'top_lip_xvel_var': 'Top Lip X-Axis Velocity Variance',\n",
    "        'top_lip_yvel_var': 'Top Lip Y-Axis Velocity Variance',\n",
    "        'bottom_lip_xvel_var': 'Bottom Lip X-Axis Velocity Variance',\n",
    "        'bottom_lip_yvel_var': 'Bottom Lip Y-Axis Velocity Variance',\n",
    "        'face_detection_percentage': 'Face Detection Percentage',\n",
    "        'label': 'Video Authenticity Label'\n",
    "    }\n",
    "    df = df.rename(columns=column_renaming)\n",
    "\n",
    "    return df, errors\n",
    "\n",
    "directory_path = \"/data1/belalm/Capstone/data/landmarks\"\n",
    "df, errors = create_dataframe_from_json(directory_path)\n",
    "\n",
    "print(df) \n",
    "\n",
    "if errors:\n",
    "    print(\"Errors encountered:\")\n",
    "    for error in errors:\n",
    "        print(error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing\n",
    "In this section, we load the preprocessed data and implement several machine learning models to assess their performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X = df.drop(['video_name', 'Video Authenticity Label'], axis=1)\n",
    "y = df['Video Authenticity Label'].map({'FAKE': 0, 'REAL': 1})  # Convert labels to binary\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Impute missing values using the mean of each column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Scale the features to be used by SVM\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.5294117647058824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.42      0.48        26\n",
      "           1       0.52      0.64      0.57        25\n",
      "\n",
      "    accuracy                           0.53        51\n",
      "   macro avg       0.53      0.53      0.52        51\n",
      "weighted avg       0.53      0.53      0.52        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Logistic Regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model using the imputed and scaled training data\n",
    "logistic_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the imputed and scaled test set\n",
    "logistic_predictions = logistic_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the Logistic Regression model\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "print(f\"Logistic Regression Accuracy: {logistic_accuracy}\")\n",
    "print(classification_report(y_test, logistic_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression CV scores: [0.48780488 0.56097561 0.65853659 0.58536585 0.65      ]\n",
      "Logistic Regression CV mean score: 0.5885365853658537\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform 5-fold cross-validation for Logistic Regression\n",
    "logistic_cv_scores = cross_val_score(logistic_model, X_train_scaled, y_train, cv=5)\n",
    "print(f\"Logistic Regression CV scores: {logistic_cv_scores}\")\n",
    "print(f\"Logistic Regression CV mean score: {logistic_cv_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Support Vector Machine model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.5490196078431373\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.42      0.49        26\n",
      "           1       0.53      0.68      0.60        25\n",
      "\n",
      "    accuracy                           0.55        51\n",
      "   macro avg       0.56      0.55      0.54        51\n",
      "weighted avg       0.56      0.55      0.54        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the SVM model\n",
    "svm_model = SVC()\n",
    "\n",
    "# Train the SVM model on the scaled data\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the scaled test set\n",
    "svm_predictions = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy}\")\n",
    "print(classification_report(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM CV scores: [0.51219512 0.53658537 0.63414634 0.58536585 0.65      ]\n",
      "SVM CV mean score: 0.5836585365853659\n"
     ]
    }
   ],
   "source": [
    "# Perform 5-fold cross-validation for SVM\n",
    "svm_cv_scores = cross_val_score(svm_model, X_train_scaled, y_train, cv=5)\n",
    "print(f\"SVM CV scores: {svm_cv_scores}\")\n",
    "print(f\"SVM CV mean score: {svm_cv_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.85      0.72        26\n",
      "           1       0.75      0.48      0.59        25\n",
      "\n",
      "    accuracy                           0.67        51\n",
      "   macro avg       0.69      0.66      0.65        51\n",
      "weighted avg       0.69      0.67      0.65        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the Random Forest model on the imputed data (no need to scale for tree-based models)\n",
    "rf_model.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Predict on the imputed test set\n",
    "rf_predictions = rf_model.predict(X_test_imputed)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy}\")\n",
    "print(classification_report(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest CV scores: [0.58536585 0.68292683 0.65853659 0.70731707 0.575     ]\n",
      "Random Forest CV mean score: 0.6418292682926829\n"
     ]
    }
   ],
   "source": [
    "# Perform 5-fold cross-validation for Random Forest\n",
    "rf_cv_scores = cross_val_score(rf_model, X_train_imputed, y_train, cv=5)\n",
    "print(f\"Random Forest CV scores: {rf_cv_scores}\")\n",
    "print(f\"Random Forest CV mean score: {rf_cv_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.5686274509803921\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.65      0.61        26\n",
      "           1       0.57      0.48      0.52        25\n",
      "\n",
      "    accuracy                           0.57        51\n",
      "   macro avg       0.57      0.57      0.56        51\n",
      "weighted avg       0.57      0.57      0.57        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the Gradient Boosting model on the imputed data\n",
    "gb_model.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Predict on the imputed test set\n",
    "gb_predictions = gb_model.predict(X_test_imputed)\n",
    "\n",
    "# Evaluate the Gradient Boosting model\n",
    "gb_accuracy = accuracy_score(y_test, gb_predictions)\n",
    "print(f\"Gradient Boosting Accuracy: {gb_accuracy}\")\n",
    "print(classification_report(y_test, gb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting CV scores: [0.53658537 0.70731707 0.58536585 0.73170732 0.6       ]\n",
      "Gradient Boosting CV mean score: 0.6321951219512194\n"
     ]
    }
   ],
   "source": [
    "# Perform 5-fold cross-validation for Gradient Boosting\n",
    "gb_cv_scores = cross_val_score(gb_model, X_train_imputed, y_train, cv=5)\n",
    "print(f\"Gradient Boosting CV scores: {gb_cv_scores}\")\n",
    "print(f\"Gradient Boosting CV mean score: {gb_cv_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this notebook, we have explored a proof of concept for deepfake detection using facial landmark variance as a distinguishing feature between real and fake videos. Our initial exploratory data analysis suggested that variances in the movement of facial landmarks could be promising indicators of video authenticity.\n",
    "\n",
    "We did this by extracting facial landmark data from a subset of our video dataset and generating features based on the variance of landmark movements. We then trained basic machine learning models, including Logistic Regression and Support Vector Machines, to classify videos as real or fake based on these features.\n",
    "\n",
    "The performance of these initial models provided encouraging results, with accuracy scores that demonstrate the potential viability of using landmark variance as a feature for deepfake detection. While the accuracy is not perfect, it is significantly better than random chance, suggesting that the features contain meaningful information about video authenticity.\n",
    "\n",
    "Next Steps \n",
    "\n",
    "1.) The results from this notebook serve as a strong foundation for our next phase of work, which involves several key steps:\n",
    "\n",
    "2.) Full Dataset Training: We will scale up our efforts by training models on the full dataset, which will likely enhance the robustness and generalizability of our findings.\n",
    "\n",
    "3.) Refined Model Development: A more sophisticated model will be developed to directly compare pairs of videos — one real and one fake — to identify the inauthentic one. This approach is expected to have high accuracy as it will leverage the subtle differnces between an original and its corresponding deepfake.\n",
    "\n",
    "Feature Engineering and Model Tuning: Further feature engineering and hyperparameter tuning will be conducted to improve the models. \n",
    "\n",
    "By following these steps, we aim to develop a robust deepfake detection system that can serve as a valuable tool in the fight against digital misinformation. Our work contributes to the broader effort to maintain integrity and trust in digital media.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
